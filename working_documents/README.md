# Old references

* E. Bair, T. Hastie, D. Paul, and R. Tibshirani.  
[**Prediction by supervised principal components**](http://dx.doi.org/10.1198/016214505000000628). Journal of the American Statistical Association, 101(473)2006.
* D. Paul, E. Bair, T. Hastie, and R. Tibshirani.  
[**`Preconditioning' for feature selection and regression in high-dimensional problems**](http://dx.doi.org/10.1214/00905360700000057). The Annals of Statistics, 36(4):1595--1618, 2008.
* V. Q. Vu and J. Lei.  
[**Minimax Sparse Principal Subspace Estimation in High Dimensions**](http://dx.doi.org/10.1214/13-AOS1151). Annals of Statistics, 41:2905--2947, 2013.
* D. Homrighausen and D. J. McDonald.  
[**On the Nyström and Column-Sampling Methods for the Approximate Principal Components Analysis of Large Data Sets**](http://dx.doi.org/10.1080/10618600.2014.995799). Journal of Computational and Graphical Statistics, 25(2):344--362, 2016.
* L. Ding and D. J. McDonald.  
[**Predicting phenotypes from microarrays using amplified, initially marginal, eigenvector regression**](http://dx.doi.org/10.1093/bioinformatics/btx265). 2017.
* R. D. Cook, L. Forzani, and others.  
[**Principal fitted components for dimension reduction in regression**](http://dx.doi.org/10.1214/08-STS275). Statistical Science, 23(4):485--501, 2008.
* L. Li and X. Yin.  
[**Sliced inverse regression with regularizations**](http://dx.doi.org/10.1111/j.1541-0420.2007.00836.x). Biometrics, 64(1):124--131, 2008.
* T. T. Cai and A. Zhang.  
[**Rate-optimal perturbation bounds for singular subspaces with applications to high-dimensional statistics**](https://arxiv.org/abs/1605.00353). 2016.
* K. P. Adragni and R. D. Cook.  
[**Sufficient dimension reduction and prediction in regression**](http://dx.doi.org/10.1098/rsta.2009.0110). Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences, 367(1906):4385--4405, 2009.
* X. Chen, C. Zou, and R. D. Cook.  
[**Coordinate-independent sparse sufficient dimension reduction and variable selection**](http://dx.doi.org/10.1214/10-AOS826). The Annals of Statistics, 38(6):3696--3723, 2010.
* L. Li.  
[**Sparse sufficient dimension reduction**](http://dx.doi.org/10.1093/biomet/asm044). Biometrika, 94(3):603--613, 2007.
* I. M. Johnstone and A. Y. Lu.  
[**Sparse principal components analysis**](https://arxiv.org/abs/0901.4392). 2009.
* B. Li and S. Wang.  
[**On directional regression for dimension reduction**](http://dx.doi.org/10.1198/016214507000000536). Journal of the American Statistical Association, 102(479):997--1008, 2007.
* A. Globerson and N. Tishby.  
[**Sufficient dimensionality reduction**](http://www.jmlr.org/papers/v3/globerson03a.html). Journal of Machine Learning Research, 3:1307--1331, 2003.
* N. Arcolano and P. J. Wolfe.  
[**Estimating principal components of covariance matrices using the Nystr\"om method**](https://arxiv.org/abs/1111.6926). 2011.
* N. Arcolano and P. J. Wolfe.  
[**Estimating principal components of large covariance matrices using the Nyström method**](http://ai2-s2-pdfs.s3.amazonaws.com/6fdc/488964a1f48b8a18e8d773b24ce8afbdd724.pdf). Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on, 3784--3787, 2011.
* Y. Yu, T. Wang, and R. J. Samworth.  
[**A useful variant of the Davis--Kahan theorem for statisticians**](http://dx.doi.org/10.1093/biomet/asv008). Biometrika, 102(2):315--323, 2014.
* J. Lei, V. Q. Vu, and others.  
[**Sparsistency and agnostic inference in sparse PCA**](http://dx.doi.org/10.1214/14-AOS1273). The Annals of Statistics, 43(1):299--322, 2015.
* T. Wang, Q. Berthet, R. J. Samworth, and others.  
[**Statistical and computational trade-offs in estimation of sparse principal components**](http://dx.doi.org/10.1214/15-AOS1369). The Annals of Statistics, 44(5):1896--1930, 2016.
* A. Kneip and K. J. Utikal.  
[**Inference for density families using functional principal component analysis**](http://dx.doi.org/10.1198/016214501753168235). Journal of the American Statistical Association, 96(454):519--542, 2001.
* W. Yang and H. Xu.  
[**Streaming Sparse Principal Component Analysis**](http://proceedings.mlr.press/v37/yangd15.html). Proceedings of the 32nd International Conference on Machine Learning, Proceedings of Machine Learning Research, 37, 494--503, 2015.
* V. Q. Vu, J. Cho, J. Lei, and K. Rohe.  
[**Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA**](http://papers.nips.cc/paper/5136-fantope-projection-and-selection-a-near-optimal-convex-relaxation-of-sparse-pca.pdf). Advances in Neural Information Processing Systems 26, 2670--2678, 2013.

# New references (10/27/2017)

*Some duplicates*

* V. Q. Vu, J. Cho, J. Lei, and K. Rohe.  
[**Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA**](http://papers.nips.cc/paper/5136-fantope-projection-and-selection-a-near-optimal-convex-relaxation-of-sparse-pca.pdf). Advances in Neural Information Processing Systems 26, 2670--2678, 2013.
* J. Wang, J. Lee, M. Mahdavi, M. Kolar, and N. Srebro.  
[**Sketching Meets Random Projection in the Dual: A Provable Recovery Algorithm for Big and High-dimensional Data**](http://proceedings.mlr.press/v54/wang17d.html). Proceedings of the 20th International Conference on Artificial Intelligence and Statistics (AISTATS), Proceedings of Machine Learning Research, 54, 1150--1158, 2017.
* L. Zhang, M. Mahdavi, R. Jin, T. Yang, and S. Zhu.  
**Random projections for classification: A recovery approach**. IEEE Transactions on Information Theory, 60(11):7300--7316, 2014.
* L. Zhang, M. Mahdavi, R. Jin, T. Yang, and S. Zhu.  
[**Recovering the Optimal Solution by Dual Random Projection**](http://proceedings.mlr.press/v30/Zhang13a.html). Proceedings of the 26th Annual Conference on Learning Theory, Proceedings of Machine Learning Research, 30, 135--157, 2013.
* Q. Li and J. Shao.  
**Sparse quadratic discriminant analysis for high dimensional data**. Statistica Sinica, 25:457--473, 2015.
* J. A. Ramey, C. K. Stein, P. D. Young, and D. M. Young.  
[**High-Dimensional Regularized Discriminant Analysis**](https://arxiv.org/abs/1602.01182). 2016.
* J. Fan, Y. Liao, and M. Mincheva.  
[**Large covariance estimation by thresholding principal orthogonal complements**](http://dx.doi.org/10.1111/rssb.12016). Journal of the Royal Statistical Society: Series B (Statistical Methodology), 75(4):603--680, 2013.
* T. I. Cannings and R. J. Samworth.  
[**Random-projection ensemble classification**](http://dx.doi.org/10.1111/rssb.12228). Journal of the Royal Statistical Society: Series B (Statistical Methodology), 79(4):959--1035, 2017.
* J. Fan, Y. Liao, and W. Wang.  
[**Projected principal component analysis in factor models**](https://doi.org/10.1214/15-AOS1364). Annals of Statistics, 44(1):219--254, 2016.
* Y. Fan, J. Jin, and Z. Yao.  
[**Optimal classification in sparse Gaussian graphic model**](https://doi.org/10.1214/13-AOS1163). Annals of Statistics, 41(5):2537--2571, 2013.
* Q. Mai and H. Zou.  
[**A Note On the Connection and Equivalence of Three Sparse Linear Discriminant Analysis Methods**](http://dx.doi.org/10.1080/00401706.2012.746208). Technometrics, 55(2):243-246, 2013.
* J. Fan, Z. T. Ke, H. Liu, and L. Xia.  
[**QUADRO: A supervised dimension reduction method via Rayleigh quotient optimization**](https://doi.org/10.1214/14-AOS1307). Annals of Statistics, 43(4):1498--1534, 2015.

